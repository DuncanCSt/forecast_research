{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d26d3bc",
   "metadata": {},
   "source": [
    "## Tune LSTM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26fe59a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3013fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as robjects\n",
    "\n",
    "folder_name = '3_state_model'\n",
    "\n",
    "data_log = pd.read_csv(folder_name + \"/close_data_log.csv\")\n",
    "\n",
    "# Helper function to convert R data.frame to pandas DataFrame\n",
    "def r_to_df(r_df):\n",
    "    return pd.DataFrame({name: np.array(r_df.rx2(name)) for name in r_df.names})\n",
    "\n",
    "# Read the RDS files using rpy2\n",
    "readRDS = robjects.r['readRDS']\n",
    "\n",
    "hmm_stats_r = readRDS(folder_name + \"/hmm_stats_df.rds\")\n",
    "hmm_stats_df = r_to_df(hmm_stats_r)\n",
    "\n",
    "hmm_state_losses = np.array(readRDS(folder_name + \"/hmm_state_losses.rds\"))\n",
    "hmm_predictions = np.array(readRDS(folder_name + \"/hmm_predictions.rds\"))\n",
    "hmm_ground_truth = np.array(readRDS(folder_name + \"/hmm_ground_truth.rds\"))\n",
    "\n",
    "X_train = np.array(readRDS(folder_name + \"/lstm_X_train.rds\"))\n",
    "Y_train = np.array(readRDS(folder_name + \"/lstm_Y_train.rds\"))\n",
    "X_valid = np.array(readRDS(folder_name + \"/lstm_X_valid.rds\"))\n",
    "Y_valid = np.array(readRDS(folder_name + \"/lstm_Y_valid.rds\"))\n",
    "X_test = np.array(readRDS(folder_name + \"/lstm_X_test.rds\"))\n",
    "Y_test = np.array(readRDS(folder_name + \"/lstm_Y_test.rds\"))\n",
    "\n",
    "n_states = Y_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7195c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 15:57:00.042970: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-26 15:57:10.873698: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769471831.863282 3631216 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1769471832.225040 3631216 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1769471834.331838 3631216 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769471834.331878 3631216 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769471834.331880 3631216 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769471834.331882 3631216 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026-01-26 15:57:14.724904: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/dcs01/.local/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Assuming X_train, Y_train, X_valid, Y_valid, and n_states are defined elsewhere\n",
    "# lookback and forecast_horizon are provided but not directly used in model building\n",
    "\n",
    "# Compute Dirichlet parameters and predicted probabilities (for reference, not used in model)\n",
    "def dirichlet_layer(evidence):\n",
    "    alpha = evidence + 1\n",
    "    S = tf.reduce_sum(alpha, axis=-1, keepdims=True)\n",
    "    probs = alpha / S\n",
    "    return probs, alpha, S\n",
    "\n",
    "# Custom evidential loss with annealing\n",
    "class EvidentialLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, annealing_rate=100.0, name='evidential_loss'):\n",
    "        super().__init__(name=name)\n",
    "        self.annealing_rate = tf.constant(annealing_rate, dtype=tf.float32)\n",
    "        self.current_epoch = tf.Variable(0.0, trainable=False, dtype=tf.float32)\n",
    "    \n",
    "    def call(self, y_true, evidence):\n",
    "        alpha = evidence + 1\n",
    "        S = tf.reduce_sum(alpha, axis=-1, keepdims=True)\n",
    "        probs = alpha / S\n",
    "        err = tf.square(y_true - probs)\n",
    "        var = probs * (1 - probs) / (S + 1)\n",
    "        \n",
    "        # Annealing factor for the regularization term\n",
    "        lambda_ = tf.minimum(1.0, self.current_epoch / self.annealing_rate)\n",
    "        \n",
    "        return tf.reduce_mean(tf.reduce_sum(err + lambda_ * var, axis=-1))\n",
    "\n",
    "# Custom callback to update the current epoch in the loss instance\n",
    "class AnnealingCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if hasattr(self.model, 'loss') and isinstance(self.model.loss, EvidentialLoss):\n",
    "            self.model.loss.current_epoch.assign(tf.cast(epoch, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33fcc5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00, 2.94924502e-13]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0, -5:, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9c8883",
   "metadata": {},
   "source": [
    "## Run hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739f40c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 00m 08s]\n",
      "val_loss: 0.22197426855564117\n",
      "\n",
      "Best val_loss So Far: 0.2187802791595459\n",
      "Total elapsed time: 00h 05m 38s\n",
      "{'lookback': 3, 'include_TSX_Composite': True, 'include_Crude_Oil_Futures': False, 'include_Gold_Futures': True, 'include_Copper_Futures': False, 'include_SP_500': True, 'lstm_units': 32, 'dense_units': 16, 'tuner/epochs': 25, 'tuner/initial_epoch': 9, 'tuner/bracket': 3, 'tuner/round': 2, 'tuner/trial_id': '0041'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m6,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,635</span> (29.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,635\u001b[0m (29.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,635</span> (29.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,635\u001b[0m (29.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forecast_horizon = 0  # Example horizon index for validation\n",
    "\n",
    "# Model-building function for hyperparameter tuning\n",
    "def build_model(hp):\n",
    "    \n",
    "    # Tune lookback (history length/timesteps)\n",
    "    lookback = hp.Choice('lookback', values=[3, 5, 10])\n",
    "    \n",
    "    # Tune feature inclusion (one boolean per group of 4 columns)\n",
    "    include_tsx = hp.Boolean('include_TSX_Composite', default=True)\n",
    "    include_crude = hp.Boolean('include_Crude_Oil_Futures', default=True)\n",
    "    include_gold = hp.Boolean('include_Gold_Futures', default=True)\n",
    "    include_copper = hp.Boolean('include_Copper_Futures', default=True)\n",
    "    include_sp500 = hp.Boolean('include_SP_500', default=True)\n",
    "    \n",
    "    # Build feature mask: 1.0 for included groups, 0.0 for excluded\n",
    "    feature_mask_list = (\n",
    "        [1.0] * 4 if include_tsx else [0.0] * 4\n",
    "    ) + (\n",
    "        [1.0] * 4 if include_crude else [0.0] * 4\n",
    "    ) + (\n",
    "        [1.0] * 4 if include_gold else [0.0] * 4\n",
    "    ) + (\n",
    "        [1.0] * 4 if include_copper else [0.0] * 4\n",
    "    ) + (\n",
    "        [1.0] * 4 if include_sp500 else [0.0] * 4\n",
    "    )\n",
    "    feature_mask = tf.constant(feature_mask_list, dtype=tf.float32)\n",
    "    \n",
    "    # Other hyperparameters (unchanged)\n",
    "    lstm_units = hp.Choice('lstm_units', values=[16, 32])\n",
    "    dense_units = hp.Choice('dense_units', values=[8, 16])\n",
    "    dropout_rate = 0.3 # hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    #learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=X_train.shape[1:]),  # Fixed shape (10, 20)\n",
    "        \n",
    "        # Lambda layer to slice to the last 'lookback' timesteps\n",
    "        layers.Lambda(lambda x: x[:, -lookback:, :]),\n",
    "        \n",
    "        # Lambda layer to apply feature mask (broadcast to (batch, timesteps, 20))\n",
    "        layers.Lambda(lambda x: x * tf.reshape(feature_mask, (1, 1, 20))),\n",
    "        \n",
    "        # LSTM layer with added dropout\n",
    "        layers.LSTM(lstm_units, dropout=dropout_rate),\n",
    "        \n",
    "        layers.Dense(dense_units, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(dense_units, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        # Output raw evidence (non-negative)\n",
    "        layers.Dense(n_states, activation='softplus')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss=EvidentialLoss(annealing_rate=100.0),\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']  # Accuracy on argmax(probs)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize the tuner (using Hyperband for efficiency)\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',  # Optimize for validation loss\n",
    "    max_epochs=75,\n",
    "    factor=3,\n",
    "    directory='tuner_dir',\n",
    "    project_name='evidential_lstm_tuning_v2'\n",
    ")\n",
    "\n",
    "# Define callbacks: annealing and early stopping\n",
    "annealing_callback = AnnealingCallback()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(\n",
    "    X_train, \n",
    "    Y_train[:, forecast_horizon, :], \n",
    "    epochs=75, \n",
    "    validation_data=(X_valid, Y_valid[:, forecast_horizon, :]),\n",
    "    callbacks=[annealing_callback, early_stopping],\n",
    "    verbose=1  # Adjust verbosity as needed\n",
    ")\n",
    "\n",
    "# Retrieve the best model and hyperparameters\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=3)[0]\n",
    "\n",
    "# Optionally, print the best hyperparameters\n",
    "print(best_hyperparameters.values)\n",
    "\n",
    "# Summary of the best model\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b0680a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lookback': 3,\n",
       " 'include_TSX_Composite': True,\n",
       " 'include_Crude_Oil_Futures': False,\n",
       " 'include_Gold_Futures': True,\n",
       " 'include_Copper_Futures': False,\n",
       " 'include_SP_500': True,\n",
       " 'lstm_units': 32,\n",
       " 'dense_units': 16,\n",
       " 'tuner/epochs': 25,\n",
       " 'tuner/initial_epoch': 9,\n",
       " 'tuner/bracket': 3,\n",
       " 'tuner/round': 2,\n",
       " 'tuner/trial_id': '0041'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters(num_trials=3)[0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d566a7",
   "metadata": {},
   "source": [
    "## Run tuning for all lookback periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038411a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3586ec73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lookback</th>\n",
       "      <th>include_TSX_Composite</th>\n",
       "      <th>include_Crude_Oil_Futures</th>\n",
       "      <th>include_Gold_Futures</th>\n",
       "      <th>include_Copper_Futures</th>\n",
       "      <th>include_SP_500</th>\n",
       "      <th>lstm_units</th>\n",
       "      <th>dense_units</th>\n",
       "      <th>tuner/epochs</th>\n",
       "      <th>tuner/initial_epoch</th>\n",
       "      <th>tuner/bracket</th>\n",
       "      <th>tuner/round</th>\n",
       "      <th>tuner/trial_id</th>\n",
       "      <th>horizon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0049</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0061</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0058</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0013</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0008</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lookback  include_TSX_Composite  include_Crude_Oil_Futures  \\\n",
       "0         3                   True                       True   \n",
       "1        10                  False                       True   \n",
       "2         5                   True                       True   \n",
       "3         3                   True                      False   \n",
       "4        10                  False                       True   \n",
       "5         3                  False                      False   \n",
       "\n",
       "   include_Gold_Futures  include_Copper_Futures  include_SP_500  lstm_units  \\\n",
       "0                  True                   False            True          32   \n",
       "1                  True                    True            True          16   \n",
       "2                 False                   False            True          32   \n",
       "3                 False                    True            True          32   \n",
       "4                 False                    True           False          32   \n",
       "5                 False                    True           False          32   \n",
       "\n",
       "   dense_units  tuner/epochs  tuner/initial_epoch  tuner/bracket  tuner/round  \\\n",
       "0           16            75                   25              3            3   \n",
       "1           16            75                   25              3            3   \n",
       "2           16            25                    9              2            1   \n",
       "3           16            25                    9              2            1   \n",
       "4            8             9                    3              3            1   \n",
       "5           16             9                    3              3            1   \n",
       "\n",
       "  tuner/trial_id  horizon  \n",
       "0           0047        0  \n",
       "1           0049        1  \n",
       "2           0061        2  \n",
       "3           0058        3  \n",
       "4           0013        4  \n",
       "5           0008        5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(best_params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "febddca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23 Complete [00h 00m 13s]\n",
      "val_loss: 0.40580233931541443\n",
      "\n",
      "Best val_loss So Far: 0.3067939281463623\n",
      "Total elapsed time: 00h 04m 49s\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "tuner_dir/evidential_lstm_tuning_h6_v2/trial_0023/trial.json; Disk quota exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResourceExhaustedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m early_stopping = EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m5\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Perform the hyperparameter search for this horizon\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mtuner\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_valid\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mannealing_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust verbosity as needed\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Retrieve the best hyperparameters for this horizon\u001b[39;00m\n\u001b[32m     33\u001b[39m best_hyperparameters = tuner.get_best_hyperparameters(num_trials=\u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:225\u001b[39m, in \u001b[36mBaseTuner.search\u001b[39m\u001b[34m(self, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    224\u001b[39m     \u001b[38;5;28mself\u001b[39m.pre_create_trial()\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m     trial = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtuner_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trial.status == trial_module.TrialStatus.STOPPED:\n\u001b[32m    227\u001b[39m         \u001b[38;5;66;03m# Oracle triggered exit.\u001b[39;00m\n\u001b[32m    228\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras_tuner/src/engine/oracle.py:108\u001b[39m, in \u001b[36msynchronized.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    106\u001b[39m     LOCKS[oracle].acquire()\n\u001b[32m    107\u001b[39m     THREADS[oracle] = thread_name\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m ret_val = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[32m    110\u001b[39m     THREADS[oracle] = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras_tuner/src/engine/oracle.py:497\u001b[39m, in \u001b[36mOracle.create_trial\u001b[39m\u001b[34m(self, tuner_id)\u001b[39m\n\u001b[32m    495\u001b[39m \u001b[38;5;28mself\u001b[39m.trials[trial_id] = trial\n\u001b[32m    496\u001b[39m \u001b[38;5;28mself\u001b[39m.start_order.append(trial_id)\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[38;5;28mself\u001b[39m.save()\n\u001b[32m    499\u001b[39m \u001b[38;5;28mself\u001b[39m._display.on_trial_begin(trial)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras_tuner/src/engine/oracle.py:805\u001b[39m, in \u001b[36mOracle._save_trial\u001b[39m\u001b[34m(self, trial)\u001b[39m\n\u001b[32m    802\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_save_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[32m    803\u001b[39m     \u001b[38;5;66;03m# Write trial status to trial directory\u001b[39;00m\n\u001b[32m    804\u001b[39m     trial_id = trial.trial_id\n\u001b[32m--> \u001b[39m\u001b[32m805\u001b[39m     \u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_trial_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrial.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras_tuner/src/engine/stateful.py:63\u001b[39m, in \u001b[36mStateful.save\u001b[39m\u001b[34m(self, fname)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, fname):\n\u001b[32m     55\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Saves this object using `get_state`.\u001b[39;00m\n\u001b[32m     56\u001b[39m \n\u001b[32m     57\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m \u001b[33;03m        String. The serialized state of the object.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras_tuner/src/utils.py:93\u001b[39m, in \u001b[36msave_json\u001b[39m\u001b[34m(path, obj)\u001b[39m\n\u001b[32m     91\u001b[39m obj_str = json.dumps(obj)\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m backend.io.File(path, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj_str\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/tensorflow/python/lib/io/file_io.py:100\u001b[39m, in \u001b[36mFileIO.write\u001b[39m\u001b[34m(self, file_content)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_content):\n\u001b[32m     99\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Writes file_content to the file. Appends to the end of the file.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prewrite_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m   \u001b[38;5;28mself\u001b[39m._writable_file.append(\n\u001b[32m    102\u001b[39m       compat.as_bytes(file_content, encoding=\u001b[38;5;28mself\u001b[39m.__encoding))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/tensorflow/python/lib/io/file_io.py:85\u001b[39m, in \u001b[36mFileIO._prewrite_check\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._write_check_passed:\n\u001b[32m     83\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m errors.PermissionDeniedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     84\u001b[39m                                      \u001b[33m\"\u001b[39m\u001b[33mFile isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt open for writing\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28mself\u001b[39m._writable_file = \u001b[43m_pywrap_file_io\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWritableFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__mode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mResourceExhaustedError\u001b[39m: tuner_dir/evidential_lstm_tuning_h6_v2/trial_0023/trial.json; Disk quota exceeded"
     ]
    }
   ],
   "source": [
    "# List to collect best hyperparameters for each horizon\n",
    "best_params_list = []\n",
    "\n",
    "# Loop through forecast horizons from 0 to 9\n",
    "for horizon in range(10):\n",
    "    print(f\"Starting hyperparameter tuning for forecast horizon: {horizon}\")\n",
    "    \n",
    "    # Initialize a new tuner for each horizon to avoid state conflicts\n",
    "    tuner = kt.Hyperband(\n",
    "        build_model,\n",
    "        objective='val_loss',  # Optimize for validation loss\n",
    "        max_epochs=75,\n",
    "        factor=3,\n",
    "        directory='tuner_dir',\n",
    "        project_name=f'evidential_lstm_tuning_h{horizon}_v2'  # Unique project name per horizon\n",
    "    )\n",
    "\n",
    "    # Define callbacks: annealing and early stopping\n",
    "    annealing_callback = AnnealingCallback()\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Perform the hyperparameter search for this horizon\n",
    "    tuner.search(\n",
    "        X_train, \n",
    "        Y_train[:, horizon, :], \n",
    "        epochs=75, \n",
    "        validation_data=(X_valid, Y_valid[:, horizon, :]),\n",
    "        callbacks=[annealing_callback, early_stopping],\n",
    "        verbose=1  # Adjust verbosity as needed\n",
    "    )\n",
    "\n",
    "    # Retrieve the best hyperparameters for this horizon\n",
    "    best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    \n",
    "    # Create a dictionary of the values and include the horizon\n",
    "    params_dict = best_hyperparameters.values.copy()\n",
    "    params_dict['horizon'] = horizon\n",
    "    \n",
    "    # Append to the list\n",
    "    best_params_list.append(params_dict)\n",
    "\n",
    "# Convert the list of dictionaries to a Pandas DataFrame\n",
    "best_params_df = pd.DataFrame(best_params_list)\n",
    "\n",
    "# Optionally, print the DataFrame\n",
    "print(best_params_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (Fir)",
   "language": "python",
   "name": "py312"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
